
#Variables
#audio_clip_band- NOISE+OGAudio
#reduced_Noise -after adaptive filter is being applied
#data- OGAudio



def fftnoise(f):
    f = np.array(f, dtype="complex")
    Np = (len(f) - 1) // 2
    phases = np.random.rand(Np) * 2 * np.pi
    phases = np.cos(phases) + 1j * np.sin(phases)
    f[1 : Np + 1] *= phases
    f[-1 : -1 - Np : -1] = np.conj(f[1 : Np + 1])
    return np.fft.ifft(f).real

  def band_limited_noise(min_freq, max_freq, samples=1024, samplerate=1): 
    freqs = np.abs(np.fft.fftfreq(samples, 1 / samplerate)) 
    f = np.zeros(samples)
    f[np.logical_and(freqs >= min_freq, freqs <= max_freq)] = 1
    return fftnoise(f)

#Domain: fftnoise operates in the frequency domain, generating noise directly in the frequency space, 
#while band_limited_noise operates in the time domain, generating noise based on specified frequency limits.

#Input: fftnoise directly takes frequency components as input, 
#while band_limited_noise takes frequency limits (min_freq and max_freq) and generates noise within that frequency range.

#Output: fftnoise returns noise in the time domain, 
#while band_limited_noise returns noise in the frequency domain.

#fftnoise generates noise directly in the frequency domain using specified phases,
#while band_limited_noise generates noise in the time domain based on specified frequency limits.


noise_len = 2 # seconds
noise = band_limited_noise(min_freq=4000, mx_freq = 12000, samples=len(data), samplerate=rate)*10
noise_clip = noise[:rate*noise_len]
audio_clip_band_limited = data+10*noise


fig, ax = plt.subplots(figsize=(20, 4))
ax.plot(data)

# Display the audio
ipd.display(ipd.Audio(data, rate=rate))




fig,ax=plt.subplots(figsize=(20,3))
ax.plot(noise)

IPython.display.Audio(data=noise,rate=rate)




#noise added
noise_len = 2 # seconds
noise = band_limited_noise(min_freq=4000, max_freq = 12000, samples=len(data), samplerate=rate)*10
noise_clip = noise[:rate*noise_len]
audio_clip_band_limited = data+10*noise

fig.ax= plt.subplots(figsize=(20,3))
ax.plot(audio_clip_band_limited)

IPython.display.Audio(data=audio_clip_band_limited,rate=rate)


#First Filter(technique is from Stationary Noise reduce)

def band_limited_noise(min_freq, samples=1024,samplerate=1):
    freqs= np.abs(np.fft.fftfreq(samples, 1/samplerate))
    f= np.zeros(samples)
    f[np.logical_and(freqs >= min_freq, freqs <= max_freq)]=1
    return fftnoise(f)
    
# stationary remove noise
import noisereduce as nr

# Assuming 'data' and 'rate' are defined elsewhere in your code
reduced_noise = nr.reduce_noise(y=data, sr=rate, n_std_thresh_stationary=1.5, stationary=True)

#filtered the voice
fig.ax= plt.subplots(figsize=(20,3))
ax.plot(reduced_noise)

IPython.display.Audio(data=reduced_noise, rate=rate)




#Noise reduce for stationary noise
noise_reduced= nr.reduce_noise(y=data, sr=rate, prop_decrease=0, stationary=False)

fig.ax= plt.subplots(figsize=(15,4))
ax.plot(reduced_noise)

fig, axs = plt.subplots(nrows=2, figsize=(15,6))
axs[0].plot(data[3000:5000])
axs[0].plot(noise_reduced[3000:5000])
axs[0].plot(data)
axs[0].plot(noise_reduced)



#sec time filter
fig, ax = plt.subplots(figsize=(15,5))
ax.plot(audio_clip_band_limited)
ax.plot(reduced_noise)

IPython.display.Audio(data=reduced_noise, rate=rate)


import time
from datetime import timedelta as td
import librosa
import scipy.signal
import numpy as np
import matplotlib.pyplot as plt

def _stft(y, n_fft, hop_length, win_length):
    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)


#y: Yeh parameter hai jo audio signal ko represent karta hai, matlab yeh batata hai ki humein kaunsa audio signal STFT mein convert karna hai.
#n_fft: Yeh parameter hai jo frequency spectrum ka size define karta hai, matlab yeh batata hai ki humein har frame ke liye kitne frequencies ko consider karna hai.
#hop_length: Yeh parameter hai jo frame ke beech ka gap define karta hai, matlab yeh batata hai ki humein har frame ke beech kaunsa duration lena hai.
#win_length: Yeh parameter hai jo window size ko define karta hai, matlab yeh batata hai ki har frame mein kaunsa duration ka audio data include karna hai.


def istft(y, hop_length, win_length):
    return librosa.istft(y, hop_length, win_length)
def amp_to_db(x):
    return librosa.core.amplitude_to_db(x, ref=1.0, amin=1e-20, top_db=80.0)
#The output is typically a numpy array containing the signal in decibels.

def db_to_amp(x):
    return librosa.core.db_to_amplitude(x, ref=1.0)


#Spectral filtering is like tuning into a specific radio station while ignoring the others around it.

def removeNoise(
    audio_clip,
    noise_clip,
    n_grad_freq=2,
    n_grad_time=4,
    n_fft=2048,
    win_length=2048,
    hop_length=512,
    n_std_thresh=1.5,
    prop_decrease=1.0,
    verbose=False,
    visual=False,
):
    # Agar verbose mode chalu hai toh shuru mein time count karo
    if verbose:
        start = time.time()
    
    # Calculate kar noise ka STFT aur uska DB (decibel) value
    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)
    noise_stft_db = amp_to_db(np.abs(noise_stft))
    
    # Noise ke upar statistics calculate karo
    mean_freq_noise = np.mean(noise_stft_db, axis=1)
    std_freq_noise = np.std(noise_stft_db, axis=1)
    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh
    
    # Agar verbose mode chalu hai toh print karo noise ka STFT calculation ka time
    if verbose:
        print("STFT on noise:", td(seconds=time.time() - start))
        start = time.time()
    
    # Signal ka STFT aur uska DB (decibel) value calculate karo
    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)
    sig_stft_db = amp_to_db(np.abs(sig_stft))
    
    # Agar verbose mode chalu hai toh print karo signal ka STFT calculation ka time
    if verbose:
        print("STFT on signal:", td(seconds=time.time() - start))
        start = time.time()
    
    # Masking ke liye value calculate karo
    mask_gain_db = np.min(amp_to_db(np.abs(sig_stft)))
    print(noise_thresh, mask_gain_db)
    
    # Smoothing filter banake rakh
    smoothing_filter = np.outer(
        np.concatenate(
            [
                np.linspace(0, 1, n_grad_freq + 1, endpoint=False),
                np.linspace(1, 0, n_grad_freq + 2),
            ]
        )[1:-1],
        np.concatenate(
            [
                np.linspace(0, 1, n_grad_freq + 1, endpoint=False),
                np.linspace(1, 0, n_grad_freq + 2),
            ]
        ),
    )
    smoothing_filter = smoothing_filter - smoothing_filter / np.sum(smoothing_filter)

    # Masking threshold ko repeat karke shape match karao
    db_thresh = np.repeat(
        np.reshape(noise_thresh, [1, len(mean_freq_noise)]),
        np.shape(sig_stft_db)[1],
        axis=0,
    ).T
    
    # Agar verbose mode chalu hai toh print karo masking ka calculation ka time
    if verbose:
        print("Masking:", td(seconds=time.time() - start))
        start = time.time()
    
    # Mask ko smoothing filter ke saath convolve karo
    sig_mask = scipy.signal.fftconvolve(sig_mask)
    print("Masking:", td(seconds=time.time() - start))
    start = time.time()
    
    # Mask ko smoothing filter ke saath convolve karo
    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode="same")
    sig_mask = sig_mask * prop_decrease
    
    # Agar verbose mode chalu hai toh print karo mask convolution ka time
    if verbose:
        print("Mask convolution:", td(seconds=time.time() - start))
        start = time.time()
    
    # Signal ko mask karo
    sig_stft_db_masked = (
        sig_stft_db * (1 - sig_mask) + np.ones(np.shape(mask_gain_db)) * mask_gain_db * sig_mask
    )
    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)
    sig_stft_amp = (
        db_to_amp(sig_stft_db_masked) * np.sign(sig_stft) + 1J * sig_imag_masked
    )
    
    # Agar verbose mode chalu hai toh print karo mask application ka time
    if verbose:
        print("Mask application:", td(seconds=time.time() - start))
        start = time.time()
    
    # Signal ko recover karo
    recovered_signal = istft(sig_stft_amp, hop_length, win_length)
    recovered_spec = amp_to_db(
        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))
    )
    
    # Agar verbose mode chalu hai toh print karo signal recovery ka time
    if verbose:
        print("Signal recovery:", td(seconds=time.time() - start))

    # Agar visual mode chalu hai toh spectrogram plots banao aur dikhao
    if visual:
        plot_spectrogram(sig_stft_db, title="Signal")
        plot_statistics_and_filter(mean_freq_noise, std_freq_noise, noise_thresh, smoothing_filter)
        plot_spectrogram(sig_mask, title="Mask applied")
        plot_spectrogram(sig_stft_db_masked, title="Masked signal")
        plot_spectrogram(recovered_spec, title="Recovered spectrogram")
    
    # Recovered signal ko return karo
    return recovered_signal

#MASKING:Masking techniques aim to identify and attenuate the noise components while preserving the integrity of the desired signal. This often entails calculating statistical measures of the noise, such as its mean and standard deviation, to establish a threshold for distinguishing noise from signal.





